{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## INITIALIZE DATA FOR PREDICTING FLIGHT DELAYS"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's to understand what are we going to do and what is Azure ML\n",
        "\n",
        "<img src=\"images/level1-azureml.png\" width=\"900\" height=\"450\" />\n",
        "\n",
        "So Data is a csv that contains delays informations from flights in 2015. This csv is inside a blob storage which is a container in Azure ML for raw Data (like a csv file)\n",
        "\n",
        "We already created a Compute Instance that is going to download the data from a public blob Storage in Azure and load it in Azure Machine Learning DataSet by executing this NoteBook\n",
        "Then we will train a model and deploy this model inside an Azure service so we can predict any future Data. This Azure service is called Endpoint in Azure ML and behind this service, Azure is actually using Kubernates Services. To deploy this model we will need a configuration file to explains how to create this service. All the config files are .yaml file here and they are use to create environment (which is where your application is running like a Docker environment), components (reusable part of codes that have inputs, outputs, parameters and do jobs such as training or deploy a model) or endpoints.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Let's have a closer look :\n",
        "\n",
        "<img src=\"images/level2-azureml.png\" width=\"900\" height=\"450\" />\n",
        "\n",
        "Stay focus on the main line in the middle. We now see Compute Clusters instead of Compute instance. Compute clusters are like Kubernate Clusters, they allow multiple nodes and so multiple executions/jobs. This is why they are better to run components. We now see Environments, this is an essential part as it is mandatory for any jobs. \n",
        "\n",
        "* In this tutorial, we created a compute instance to play around with our notebook and test rapidly our code\n",
        "\n",
        "* To begin with, we are going to use this compute to dowload our Data (this notebook)\n",
        "\n",
        "* Additionally, we are going to create our own custom environment for our jobs\n",
        "\n",
        "* Afer this, we will create components for analysis and training\n",
        "\n",
        "* Ultimately, we will create our endpoint for our trained model "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the DataSet for our pipeline\n",
        "The goal of this notebook is to download the data from a public blob Storage in Azure and load it in Azure Machine Learning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be sure to log in while entering for the first time into Azure ML Studio/Compute in Notebook (Should appear on top)\n",
        "\n",
        "<img src=\"images/LogIn.png\" width=\"900\" height=\"280\" />\n",
        "\n",
        "If you are logged inside the compute, then you should set the values inside the \"\" of the code below (to get a handle to our workspace) :\n",
        "\n",
        "To get the values : Click on the Top Left :\n",
        "\n",
        "<img src=\"images/credentials.png\" width=\"900\" height=\"380\" />\n",
        "\n",
        "And GET your :\n",
        "* Subscription ID (for subscription_id)\n",
        "* Resource Group (for resource_group_name)\n",
        "* Current Workspace (workspace_name)\n",
        "\n",
        "<img src=\"images/values.png\" width=\"582\" height=\"911\" />\n",
        "\n",
        "The tenant ID is the Directory ID, you can find it here : https://portal.azure.com/#settings/directory\n",
        "\n",
        "<img src=\"images/tenantID.png\" width=\"600\" height=\"185\" />\n",
        "\n",
        "GET the :\n",
        "* Directory ID (for tenant_id)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up the Variables in the NoteBook (IMPORTANT)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install Azure-Ai-Ml into our Compute Instance Environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-ai-ml\n  Downloading azure_ai_ml-1.2.0-py3-none-any.whl (4.0 MB)\n\u001b[K     |████████████████████████████████| 4.0 MB 4.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.4.0)\nRequirement already satisfied: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.1.7)\nCollecting pydash<6.0.0\n  Downloading pydash-5.1.2-py3-none-any.whl (84 kB)\n\u001b[K     |████████████████████████████████| 84 kB 2.3 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.64.1)\nCollecting azure-storage-file-datalake<13.0.0\n  Downloading azure_storage_file_datalake-12.9.1-py3-none-any.whl (238 kB)\n\u001b[K     |████████████████████████████████| 238 kB 33.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.6.1)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.16.0)\nCollecting strictyaml<2.0.0\n  Downloading strictyaml-1.6.2.tar.gz (130 kB)\n\u001b[K     |████████████████████████████████| 130 kB 32.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (6.0)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.3.2)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\nCollecting marshmallow<4.0.0,>=3.5\n  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n\u001b[K     |████████████████████████████████| 49 kB 1.8 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: azure-core!=1.22.0,<2.0.0,>=1.8.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.26.0)\nRequirement already satisfied: colorama<0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (2.4.0)\nCollecting azure-storage-file-share<13.0.0\n  Downloading azure_storage_file_share-12.10.1-py3-none-any.whl (252 kB)\n\u001b[K     |████████████████████████████████| 252 kB 50.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (1.7.0)\nRequirement already satisfied: opencensus<1.0.0,>=0.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.0)\nRequirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.3)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (2.28.1)\nRequirement already satisfied: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from isodate->azure-ai-ml) (1.16.0)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (22.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.18.1)\nRequirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (5.10.0)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (1.3.10)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (2022.9.24)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (38.0.1)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (21.3)\nRequirement already satisfied: msal-extensions~=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.1)\nRequirement already satisfied: msal<2.0.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.20.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.10.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.26.12)\nRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (3.9.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (1.15.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.5->azure-ai-ml) (3.0.9)\nRequirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions~=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.6.0)\nCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n\u001b[K     |████████████████████████████████| 409 kB 38.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.13.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.56.4)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (2.21)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.2.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.2.8)\nRequirement already satisfied: pyasn1>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.4.8)\nBuilding wheels for collected packages: strictyaml\n  Building wheel for strictyaml (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for strictyaml: filename=strictyaml-1.6.2-py3-none-any.whl size=123923 sha256=892681da6122d618fa6ceea7dbd62d1f2ac656d2a176b4ae5465e498061580cb\n  Stored in directory: /home/azureuser/.cache/pip/wheels/e9/0b/fc/5beda6bad2ff803e820e157845679794a18f83e442da1e9f4d\nSuccessfully built strictyaml\n\u001b[31mERROR: tensorflow 2.2.1 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 3.7.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow 2.2.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.21.6 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-gpu 2.2.1 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 3.7.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-gpu 2.2.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.21.6 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-cpu 2.2.1 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 3.7.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-cpu 2.2.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.21.6 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorboardx 2.5.1 has requirement protobuf<=3.20.1,>=3.8.0, but you'll have protobuf 4.21.12 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorboard 2.2.2 has requirement google-auth<2,>=1.6.3, but you'll have google-auth 2.13.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: ray 2.0.0 has requirement click<=8.0.4,>=7.0, but you'll have click 8.1.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: ray 2.0.0 has requirement grpcio<=1.43.0,>=1.28.1; python_version < \"3.10\", but you'll have grpcio 1.50.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: ray 2.0.0 has requirement protobuf<4.0.0,>=3.15.3, but you'll have protobuf 4.21.12 which is incompatible.\u001b[0m\n\u001b[31mERROR: onnx 1.12.0 has requirement protobuf<=3.20.1,>=3.12.2, but you'll have protobuf 4.21.12 which is incompatible.\u001b[0m\n\u001b[31mERROR: azureml-automl-runtime 1.47.0 has requirement protobuf<=3.20.1, but you'll have protobuf 4.21.12 which is incompatible.\u001b[0m\n\u001b[31mERROR: autokeras 1.0.16 has requirement tensorflow<=2.5.0,>=2.3.0, but you'll have tensorflow 2.2.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: azure-storage-file-datalake 12.9.1 has requirement azure-storage-blob<13.0.0,>=12.14.1, but you'll have azure-storage-blob 12.13.0 which is incompatible.\u001b[0m\nInstalling collected packages: pydash, azure-storage-file-datalake, strictyaml, marshmallow, azure-storage-file-share, azure-ai-ml, protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.1\n    Uninstalling protobuf-3.20.1:\n      Successfully uninstalled protobuf-3.20.1\nSuccessfully installed azure-ai-ml-1.2.0 azure-storage-file-datalake-12.9.1 azure-storage-file-share-12.10.1 marshmallow-3.19.0 protobuf-4.21.12 pydash-5.1.2 strictyaml-1.6.2\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO : Replace with your own values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile setenv.py\n",
        "import os\n",
        "\n",
        "# TODO: Replace with your own subscription key\n",
        "# You can find your information in the Azure portal Machine, see above for details\n",
        "\n",
        "os.environ['subscription_id'] = \"\" # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
        "os.environ['resource_group'] = \"\" # this will look like \"rg-xxx-xxx\"\n",
        "os.environ['workspace_name'] = \"flights-mlbox\" # this will look like \"flights-mlbox\"\n",
        "\n",
        "os.environ['owner'] = \"user\" # this is your user name or you email address\n",
        "os.environ['tenant_id'] = \"\" # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing setenv.py\n"
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gather the environment variables and get the handle of our workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import os\n",
        "from azure.ai.ml import MLClient\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Execute the script\n",
        "%run setenv.py\n",
        "\n",
        "file = open(\"setenv.sh\",\"w\")\n",
        "file.write(\"export subscription_id=\" + os.environ['subscription_id'] + \"\\n\" + \"export resource_group=\" + os.environ['resource_group'] + \"\\n\" + \"export workspace_name=\" + os.environ['workspace_name'] + \"\\n\" + \"export owner=\" + os.environ['owner'] + \"\\n\" + \"export tenant_id=\" + os.environ['tenant_id'] + \"\\n\")\n",
        "file.close()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id= os.environ['subscription_id'],\n",
        "    resource_group_name= os.environ['resource_group'],\n",
        "    workspace_name= os.environ['workspace_name']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1671101312831
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Checking Credentials\n",
        "\n",
        "ml_client is lazy. So your credentials might be invalid. Run this cell to make sure your credentials are correct :"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if credentials are valid\n",
        "from IPython.display import Image\n",
        "from colorama import Fore\n",
        "\n",
        "try :\n",
        "    ml_client.begin_create_or_update(ml_client.workspaces.get())\n",
        "    print(Fore.GREEN + \"Credentials are valid\")\n",
        "except :\n",
        "    print(Fore.RED + \"Credentials are invalid - please check the TODO CELL\")\n",
        "    print(\"Please check your credentials : subscription_id, resource_group_name, workspace_name must be correct\")\n",
        "    display(Image(filename='images/credentials.PNG'))\n",
        "    print(\"You can find your credentials by clicking on the TOP LEFT of the Azure Portal ML Studio\")\n",
        "    display(Image(filename='images/values.png'))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[32mCredentials are valid\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1671101376818
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download in local a public blob storage account that contains all the data we need, then we create a Dataset that contains every files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "import os\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import shutil\n",
        "\n",
        "dataset_dir = \"./Datasets\"\n",
        "\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "account_url = \"https://publicdataflights.blob.core.windows.net/\"\n",
        "\n",
        "blob_service_client = BlobServiceClient(account_url=account_url)\n",
        "\n",
        "\n",
        "# download all blob into local files\n",
        "container_name = 'dataflights'\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blob_list = container_client.list_blobs()\n",
        "for blob in blob_list:\n",
        "    print(blob.name)\n",
        "    blob_client = blob_service_client.get_blob_client(container_name, blob=blob.name)\n",
        "    with open(os.path.join(dataset_dir, blob.name), \"wb\") as my_blob:\n",
        "        blob_data = blob_client.download_blob()\n",
        "        blob_data.readinto(my_blob)\n",
        "        print(\"\\tBlob '{}' downloaded\".format(blob.name))\n",
        "\n",
        "\n",
        "# Create a dataset from the local file\n",
        "\n",
        "dataset_name = \"dataset-delays-flights\"\n",
        "\n",
        "dataset = Data(\n",
        "    name=dataset_name,\n",
        "    description=\"Dataset for delays flights prediction 2015\",\n",
        "    tags={\"ama_owner\": \"romain.caret\"},\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    path=dataset_dir,\n",
        ")\n",
        "\n",
        "dataset = ml_client.data.create_or_update(dataset)\n",
        "\n",
        "print(\n",
        "    f\"Dataset with name {dataset.name} is registered to workspace, the dataset version is {dataset.version}\"\n",
        ")\n",
        "\n",
        "# Delete the local files\n",
        "\n",
        "if os.path.isdir(dataset_dir):\n",
        "    shutil.rmtree(dataset_dir)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "airline_codes.csv\n\tBlob 'airline_codes.csv' downloaded\nairlines.csv\n\tBlob 'airlines.csv' downloaded\nairports.csv\n\tBlob 'airports.csv' downloaded\nflights.csv\n\tBlob 'flights.csv' downloaded\nDataset with name dataset-delays-flights is registered to workspace, the dataset version is 1\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Your file exceeds 100 MB. If you experience low upload speeds or latency, we recommend using the AzCopy tool for this file transfer. See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n\u001b[32mUploading Datasets (592.49 MBs): 100%|██████████| 592487593/592487593 [00:03<00:00, 162888587.24it/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1671101450984
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
