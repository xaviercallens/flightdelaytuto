{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## INITIALIZE DATA FOR PREDICTING FLIGHT DELAYS"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's to understand what are we going to do and what is Azure ML\n",
        "\n",
        "<img src=\"images/level1-azureml.png\" width=\"900\" height=\"500\" />\n",
        "\n",
        "So Data is a csv that contains delays informations from flights in 2015. This csv is inside a blob storage which is a container in Azure ML for raw Data (like a csv file)\n",
        "\n",
        "We already created a Compute Instance that is going to download the data from a public blob Storage in Azure and load it in Azure Machine Learning DataSet by executing this NoteBook\n",
        "Then we will train a model and deploy this model inside an Azure service so we can predict any future Data. This Azure service is called Endpoint in Azure ML and behind this service, Azure is actually using Kubernates Services. To deploy this model we will need a configuration file to explains how to create this service. All the config files are .yaml file here and they are use to create environment (which is where your application is running like a Docker environment), components (reusable part of codes that have inputs, outputs, parameters and do jobs such as training or deploy a model) or endpoints.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Let's have a closer look :\n",
        "\n",
        "<img src=\"images/level2-azureml.png\" width=\"900\" height=\"500\" />\n",
        "\n",
        "Stay focus on the main line in the middle. We now see Compute Clusters instead of Compute instance. Compute clusters are like Kubernate Clusters, they allow multiple nodes and so multiple executions/jobs. This is why they are better to run components. We now see Environments, this is an essential part as it is mandatory for any jobs. \n",
        "\n",
        "* In this tutorial, we created a compute instance to play around with our notebook and test rapidly our code\n",
        "\n",
        "* To begin with, we are going to use this compute to dowload our Data (this notebook)\n",
        "\n",
        "* Additionally, we are going to create our own custom environment for our jobs\n",
        "\n",
        "* Afer this, we will create components for analysis and training\n",
        "\n",
        "* Ultimately, we will create our endpoint for our trained model "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the DataSet for our pipeline\n",
        "The goal of this notebook is to download the data from a public blob Storage in Azure and load it in Azure Machine Learning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be sure to log in while entering for the first time into Azure ML Studio/Compute in Notebook (Should appear on top)\n",
        "\n",
        "<img src=\"images/LogIn.png\" width=\"900\" height=\"280\" />\n",
        "\n",
        "If you are logged inside the compute, then you should set the values inside the \"\" of the code below (to get a handle to our workspace) :\n",
        "\n",
        "To get the values : Click on the Top Left :\n",
        "\n",
        "<img src=\"images/credentials.png\" width=\"900\" height=\"380\" />\n",
        "\n",
        "And Copy your :\n",
        "* Subscription ID (for subscription_id)\n",
        "* Resource Group (for resource_group_name)\n",
        "* Current Workspace (workspace_name)\n",
        "\n",
        "<img src=\"images/values.png\" width=\"582\" height=\"911\" />\n",
        "\n",
        "We install Azure-Ai-Ml into our Compute Instance Environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "os.environ['subscription_id'] = \"8b5374c5-8b98-45fb-bd96-7d5a4ce4e527\" # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
        "os.environ['resource_group'] = \"rg-sbx-aiops\" # this will look like \"rg-xxx-xxx\"\n",
        "os.environ['workspace_name'] = \"romain-mlbox\" # this will look like \"flights-mlbox\"\n",
        "\n",
        "print(os.environ['subscription_id'])\n",
        "print(os.environ['resource_group'])\n",
        "print(os.environ['workspace_name'])\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id= os.environ['subscription_id'],\n",
        "    resource_group_name= os.environ['resource_group'],\n",
        "    workspace_name= os.environ['workspace_name']\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "8b5374c5-8b98-45fb-bd96-7d5a4ce4e527\nrg-sbx-aiops\nromain-mlbox\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1669977738023
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Checking Credentials\n",
        "\n",
        "ml_client is lazy. So your credentials might be invalid. Run this cell to make sure your credentials are correct :"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if credentials are valid\n",
        "from IPython.display import Image\n",
        "\n",
        "try :\n",
        "    ml_client.begin_create_or_update(ml_client.workspaces.get())\n",
        "    print(\"Credentials are valid\")\n",
        "except :\n",
        "    print(\"Credentials are invalid\")\n",
        "    print(\"Please check your credentials : subscription_id, resource_group_name, workspace_name must be correct\")\n",
        "    display(Image(filename='images/credentials.PNG'))\n",
        "    print(\"You can find your credentials by clicking on the TOP LEFT of the Azure Portal ML Studio\")\n",
        "    display(Image(filename='images/values.png'))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Credentials are valid\n"
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download in local a public blob storage account that contains all the data we need, then we create a Dataset that contains every files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "import os\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import shutil\n",
        "\n",
        "dataset_dir = \"./Datasets\"\n",
        "\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "account_url = \"https://publicdataflights.blob.core.windows.net/\"\n",
        "\n",
        "blob_service_client = BlobServiceClient(account_url=account_url)\n",
        "\n",
        "\n",
        "# download all blob into local files\n",
        "container_name = 'dataflights'\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blob_list = container_client.list_blobs()\n",
        "for blob in blob_list:\n",
        "    print(blob.name)\n",
        "    blob_client = blob_service_client.get_blob_client(container_name, blob=blob.name)\n",
        "    with open(os.path.join(dataset_dir, blob.name), \"wb\") as my_blob:\n",
        "        blob_data = blob_client.download_blob()\n",
        "        blob_data.readinto(my_blob)\n",
        "        print(\"\\tBlob '{}' downloaded\".format(blob.name))\n",
        "\n",
        "\n",
        "# Create a dataset from the local file\n",
        "\n",
        "dataset_name = \"dataset-delays-flights\"\n",
        "\n",
        "dataset = Data(\n",
        "    name=dataset_name,\n",
        "    description=\"Dataset for delays flights prediction 2015\",\n",
        "    tags={\"ama_owner\": \"romain.caret\"},\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    path=dataset_dir,\n",
        ")\n",
        "\n",
        "dataset = ml_client.data.create_or_update(dataset)\n",
        "\n",
        "print(\n",
        "    f\"Dataset with name {dataset.name} is registered to workspace, the dataset version is {dataset.version}\"\n",
        ")\n",
        "\n",
        "# Delete the local files\n",
        "\n",
        "if os.path.isdir(dataset_dir):\n",
        "    shutil.rmtree(dataset_dir)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "airline_codes.csv\n\tBlob 'airline_codes.csv' downloaded\nairlines.csv\n\tBlob 'airlines.csv' downloaded\nairports.csv\n\tBlob 'airports.csv' downloaded\nflights.csv\n\tBlob 'flights.csv' downloaded\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Your file exceeds 100 MB. If you experience low upload speeds or latency, we recommend using the AzCopy tool for this file transfer. See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset with name dataset-delays-flights is registered to workspace, the dataset version is 2\n"
        }
      ],
      "execution_count": 8,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}